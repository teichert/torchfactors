{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-2.2.2-py3-none-any.whl (346 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.8/346.8 KB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting ipywidgets\n",
      "  Downloading ipywidgets-7.7.0-py2.py3-none-any.whl (123 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.4/123.4 KB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jupyter\n",
      "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
      "Collecting Pillow\n",
      "  Downloading Pillow-9.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: ipykernel in /home/adam/.cache/pypoetry/virtualenvs/torchfactors-agsvsqrc-py3.10/lib/python3.10/site-packages (5.5.6)\n",
      "Collecting ipykernel\n",
      "  Downloading ipykernel-6.13.0-py3-none-any.whl (131 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.8/131.8 KB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.12.0-cp310-cp310-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting matplotlib\n",
      "  Downloading matplotlib-3.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/11.9 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/adam/.cache/pypoetry/virtualenvs/torchfactors-agsvsqrc-py3.10/lib/python3.10/site-packages/pip/_vendor/urllib3/response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"/home/adam/.cache/pypoetry/virtualenvs/torchfactors-agsvsqrc-py3.10/lib/python3.10/site-packages/pip/_vendor/urllib3/response.py\", line 519, in read\n",
      "    data = self._fp.read(amt) if not fp_closed else b\"\"\n",
      "  File \"/home/adam/.cache/pypoetry/virtualenvs/torchfactors-agsvsqrc-py3.10/lib/python3.10/site-packages/pip/_vendor/cachecontrol/filewrapper.py\", line 90, in read\n",
      "    data = self.__fp.read(amt)\n",
      "  File \"/usr/lib/python3.10/http/client.py\", line 465, in read\n",
      "    s = self.fp.read(amt)\n",
      "  File \"/usr/lib/python3.10/socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/usr/lib/python3.10/ssl.py\", line 1273, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/usr/lib/python3.10/ssl.py\", line 1129, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/adam/.cache/pypoetry/virtualenvs/torchfactors-agsvsqrc-py3.10/lib/python3.10/site-packages/pip/_internal/cli/base_command.py\", line 167, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "  File \"/home/adam/.cache/pypoetry/virtualenvs/torchfactors-agsvsqrc-py3.10/lib/python3.10/site-packages/pip/_internal/cli/req_command.py\", line 205, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"/home/adam/.cache/pypoetry/virtualenvs/torchfactors-agsvsqrc-py3.10/lib/python3.10/site-packages/pip/_internal/commands/install.py\", line 339, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "  File \"/home/adam/.cache/pypoetry/virtualenvs/torchfactors-agsvsqrc-py3.10/lib/python3.10/site-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 94, in resolve\n",
      "    result = self._result = resolver.resolve(\n",
      "  File \"/home/adam/.cache/pypoetry/virtualenvs/torchfactors-agsvsqrc-py3.10/lib/python3.10/site-packages/pip/_vendor/resolvelib/resolvers.py\", line 481, in resolve\n",
      "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
      "  File \"/home/adam/.cache/pypoetry/virtualenvs/torchfactors-agsvsqrc-py3.10/lib/python3.10/site-packages/pip/_vendor/resolvelib/resolvers.py\", line 348, in resolve\n",
      "    self._add_to_criteria(self.state.criteria, r, parent=None)\n",
      "  File \"/home/adam/.cache/pypoetry/virtualenvs/torchfactors-agsvsqrc-py3.10/lib/python3.10/site-packages/pip/_vendor/resolvelib/resolvers.py\", line 172, in _add_to_criteria\n",
      "    if not criterion.candidates:\n",
      "  File \"/home/adam/.cache/pypoetry/virtualenvs/torchfactors-agsvsqrc-py3.10/lib/python3.10/site-packages/pip/_vendor/resolvelib/structs.py\", line 151, in __bool__\n",
      "    return bool(self._sequence)\n",
      "  File \"/home/adam/.cache/pypoetry/virtualenvs/torchfactors-agsvsqrc-py3.10/lib/python3.10/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 155, in __bool__\n",
      "    return any(self)\n",
      "  File \"/home/adam/.cache/pypoetry/virtualenvs/torchfactors-agsvsqrc-py3.10/lib/python3.10/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 143, in <genexpr>\n",
      "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
      "  File \"/home/adam/.cache/pypoetry/virtualenvs/torchfactors-agsvsqrc-py3.10/lib/python3.10/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 47, in _iter_built\n",
      "    candidate = func()\n",
      "  File \"/home/adam/.cache/pypoetry/virtualenvs/torchfactors-agsvsqrc-py3.10/lib/python3.10/site-packages/pip/_internal/resolution/resolvelib/factory.py\", line 215, in _make_candidate_from_link\n",
      "    self._link_candidate_cache[link] = LinkCandidate(\n",
      "  File \"/home/adam/.cache/pypoetry/virtualenvs/torchfactors-agsvsqrc-py3.10/lib/python3.10/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 288, in __init__\n",
      "    super().__init__(\n",
      "  File \"/home/adam/.cache/pypoetry/virtualenvs/torchfactors-agsvsqrc-py3.10/lib/python3.10/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 158, in __init__\n",
      "    self.dist = self._prepare()\n",
      "  File \"/home/adam/.cache/pypoetry/virtualenvs/torchfactors-agsvsqrc-py3.10/lib/python3.10/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 227, in _prepare\n",
      "    dist = self._prepare_distribution()\n",
      "  File \"/home/adam/.cache/pypoetry/virtualenvs/torchfactors-agsvsqrc-py3.10/lib/python3.10/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 299, in _prepare_distribution\n",
      "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
      "  File \"/home/adam/.cache/pypoetry/virtualenvs/torchfactors-agsvsqrc-py3.10/lib/python3.10/site-packages/pip/_internal/operations/prepare.py\", line 487, in prepare_linked_requirement\n",
      "    return self._prepare_linked_requirement(req, parallel_builds)\n",
      "  File \"/home/adam/.cache/pypoetry/virtualenvs/torchfactors-agsvsqrc-py3.10/lib/python3.10/site-packages/pip/_internal/operations/prepare.py\", line 532, in _prepare_linked_requirement\n",
      "    local_file = unpack_url(\n",
      "  File \"/home/adam/.cache/pypoetry/virtualenvs/torchfactors-agsvsqrc-py3.10/lib/python3.10/site-packages/pip/_internal/operations/prepare.py\", line 214, in unpack_url\n",
      "    file = get_http_url(\n",
      "  File \"/home/adam/.cache/pypoetry/virtualenvs/torchfactors-agsvsqrc-py3.10/lib/python3.10/site-packages/pip/_internal/operations/prepare.py\", line 94, in get_http_url\n",
      "    from_path, content_type = download(link, temp_dir.path)\n",
      "  File \"/home/adam/.cache/pypoetry/virtualenvs/torchfactors-agsvsqrc-py3.10/lib/python3.10/site-packages/pip/_internal/network/download.py\", line 146, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"/home/adam/.cache/pypoetry/virtualenvs/torchfactors-agsvsqrc-py3.10/lib/python3.10/site-packages/pip/_internal/cli/progress_bars.py\", line 304, in _rich_progress_bar\n",
      "    for chunk in iterable:\n",
      "  File \"/home/adam/.cache/pypoetry/virtualenvs/torchfactors-agsvsqrc-py3.10/lib/python3.10/site-packages/pip/_internal/network/utils.py\", line 63, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"/home/adam/.cache/pypoetry/virtualenvs/torchfactors-agsvsqrc-py3.10/lib/python3.10/site-packages/pip/_vendor/urllib3/response.py\", line 576, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"/home/adam/.cache/pypoetry/virtualenvs/torchfactors-agsvsqrc-py3.10/lib/python3.10/site-packages/pip/_vendor/urllib3/response.py\", line 512, in read\n",
      "    with self._error_catcher():\n",
      "  File \"/usr/lib/python3.10/contextlib.py\", line 153, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/home/adam/.cache/pypoetry/virtualenvs/torchfactors-agsvsqrc-py3.10/lib/python3.10/site-packages/pip/_vendor/urllib3/response.py\", line 443, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the '/home/adam/.cache/pypoetry/virtualenvs/torchfactors-agsvsqrc-py3.10/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U datasets ipywidgets jupyter Pillow ipykernel torchvision matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/adam/projects/torchfactors/examples/mnist.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/adam/projects/torchfactors/examples/mnist.ipynb#ch0000002vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m load_dataset\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/adam/projects/torchfactors/examples/mnist.ipynb#ch0000002vscode-remote?line=1'>2</a>\u001b[0m mnist \u001b[39m=\u001b[39m load_dataset(\u001b[39m'\u001b[39m\u001b[39mmnist\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "mnist = load_dataset('mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Subject and Transform the Raw Data\n",
    "A torchfactors model requires first describing what variables are being modeled.\n",
    "We use the name \"Subject\" to refer to the collections of variables and other\n",
    "information associated with an example instance.\n",
    "\n",
    "It is often convenient to define a method that will create an instance from\n",
    "available raw data and annotations (e.g. the `from_huggin` method below).\n",
    "\n",
    "In this example, our subject is composed of a discrete 10-way variable\n",
    "representing the which digit it is (0-9), and a two-dimensional array of binary\n",
    "variables representing a thresholded maximum pixel value for a corresponding\n",
    "patch of the image.\n",
    "\n",
    "We use the first `n_train` examples as the training_set, and form `n_dev_sets` separate development test sets of size `n_dev` by starting at the end of the available data and working backward (that way the dev sets are consistent regardless of the size of the training set).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from typing import Iterable\n",
    "import torchfactors as tx\n",
    "import torch\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class MNISTExample(tx.Subject):\n",
    "    pixels: tx.Var = tx.VarField(tx.Range(2), tx.OBSERVED)\n",
    "    digit: tx.Var = tx.VarField(tx.Range(10), tx.ANNOTATED)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_huggin(cls, example, row_scale=1, col_scale=1, threshold=125):\n",
    "        cols, rows = example['image'].size\n",
    "        pixels = torch.tensor(\n",
    "                [[float(example['image'].getpixel((c,r)))\n",
    "                  for c in range(cols)]\n",
    "                 for r in range(rows)])\n",
    "        scaled = torch.tensor(\n",
    "                [[pixels[(r-row_scale):r, (c-col_scale):c].max()\n",
    "                   for c in range(col_scale, cols+1, col_scale)]\n",
    "                  for r in range(row_scale, rows+1, row_scale)]).float()\n",
    "        return MNISTExample(\n",
    "            pixels=tx.TensorVar((scaled >= threshold).int()),\n",
    "            digit=tx.TensorVar(torch.tensor(example['label']))\n",
    "        )\n",
    "\n",
    "# create subject instances from raw data\n",
    "train_raw = mnist['train']\n",
    "n_full = len(train_raw)\n",
    "n_train = 5000\n",
    "n_dev = 5000\n",
    "n_dev_splits = 5\n",
    "scale = 9\n",
    "\n",
    "index_ranges = dict(\n",
    "    train=range(n_train),\n",
    "    **{\n",
    "        f'dev{i}': range(end - n_dev, end)\n",
    "        for i, end in enumerate(range(n_full, n_train, -n_dev)[:n_dev_splits])\n",
    "    })\n",
    "\n",
    "subjects = {\n",
    "    name: [MNISTExample.from_huggin(train_raw[i], row_scale=scale, col_scale=scale) for i in index_range]\n",
    "    for name, index_range in index_ranges.items()\n",
    "}\n",
    "\n",
    "# display some examples\n",
    "num_examples_to_show = 3\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "for i, xi in enumerate(subjects['train'][:num_examples_to_show]):\n",
    "    plt.figure(i)\n",
    "    plt.title(f'{int(xi.digit.tensor)}')\n",
    "    plt.imshow(xi.pixels.tensor.numpy())\n",
    "\n",
    "batches = {\n",
    "    name: tx.Subject.stack(subs)\n",
    "    for name, subs in subjects.items()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Model\n",
    "The model (family) is described as a class (specialized for the specified type\n",
    "of Subject) that will hold all relevant parameters and defines a method that\n",
    "generates factors given an instance of the subject type. The method may also\n",
    "create additional latent variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-21 22:03:31,601 loading...\n",
      "2022-01-21 22:03:31,604 done loading.\n",
      "Subjects...: 100%|██████████| 1/1 [00:00<00:00,  2.10it/s]\n",
      "2022-01-21 22:03:32,094 staring training...\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "class CRF(tx.Model[MNISTExample]):\n",
    "    def factors(self, x: MNISTExample) -> Iterable[tx.Factor]:\n",
    "        rows, cols = x.pixels.shape[-2:]\n",
    "        for r in range(rows):\n",
    "            for c in range(cols):\n",
    "                cell = x.pixels[...,r,c]\n",
    "                yield tx.LinearFactor(self.namespace(f'unigram_{r}_{c}'), cell, x.digit)\n",
    "                if r > 0:\n",
    "                    above_cell = x.pixels[...,r-1,c]\n",
    "                    yield tx.LinearFactor(self.namespace(f'bigram_with_above'), cell, above_cell, x.digit)\n",
    "                if c > 0:\n",
    "                    left_cell = x.pixels[...,r,c-1]\n",
    "                    yield tx.LinearFactor(self.namespace(f'bigram_with_left'), cell, left_cell, x.digit)\n",
    "                    # if r > 0:\n",
    "                    #     corner_cell = x.pixels[...,r-1,c-1]\n",
    "                    #     yield tx.LinearFactor(self.namespace(f'corner'), cell, corner_cell, x.digit)\n",
    "                    #         yield tx.LinearFactor(self.namespace(f'position_{r}_{c}'), cell, input=x.digit.tensor)\n",
    "\n",
    "system = tx.learning.example_fit_model(CRF(), subjects['train'], iterations=50, batch_size=n_train, lr=0.5, weight_decay=10.0)\n",
    "for x in batches.values():\n",
    "    x.pixels.clamp_annotated()\n",
    "    \n",
    "predictions = {\n",
    "    name: system.predict(batch)\n",
    "    for name, batch in batches.items()\n",
    "}\n",
    "accuracies = {\n",
    "    name: (batches[name].digit.tensor == predictions[name].digit.tensor).float().mean()\n",
    "    for name in predictions\n",
    "}\n",
    "print(accuracies)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6ddcf3bc0a5ad9a93d4e85e07e518f58ecae8e832077ac04390c3ad37877f120"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('torchfactors-agsvsqrc-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
